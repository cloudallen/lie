\section{Lie Algebras: Basics}
Inspired by the properties satisfied by Lie Algebras of matrix groups, we will define general Lie Algebras by those properties.
\begin{defi}
A Lie Algebra is an $\F$-algebra $\g$ with a product (represented by $[\ ,\ ]$) satisfying, for all $X, Y \text{ and }Z \in \g$:
\begin{enumerate}[label=(\alph*)]
	\item $[X,X]=0$ (Anti-Commutativity)
	\item $[X,[Y,Z]]+[Y,[Z,X]]+[Z,[X,Y]]=0$ (Jacobi Identity)
\end{enumerate}
\label{13LieAlgebra}
\end{defi}
In the case of matrices, we generally define $[X,Y]=XY-YX$ and the properties are easily verified:
\begin{enumerate}[label=(\alph*)]
	\item $[X,X]=X^2-X^2 = 0$
	\item $[X,[Y,Z]]+[Y,[Z,X]]+[Z,[X,Y]]=(XYZ - XZY - YZX + ZYX) + (YZX - YXZ - ZXY + XZY) + (ZXY - ZYX-XYZ+YXZ)=0$
\end{enumerate}
and therefore we prove that the set of all $n\times n$ matrices, in fact over any field is a Lie Algebra with the commutator, there is nothing special about finite dimensions or a specific base here, and if we extend this to endomorphisms on a vector space $V$ over $\F$ we can denote the Lie Algebra by $\gl(V)$ or denoted by $\gl(n,\F)$ with matrices, in respect to the basis $\{e_{ij}\}, 1\le i,j \le n$ the Lie Bracket is given directly by: $[e_{ij},e_{kl}] = \delta_{jk}e_{il} - \delta_{il}e_{kj}$ in the finite dimensional case.
\begin{ex}
	Matrix Algebras
	\begin{enumerate}
		\item $\gsl(n,\F) = \{X \in \gl(n,\F)|\Tr(X)=0\}$, since $\Tr:\gl \rightarrow \F$ is a linear form then $\gsl$ is a vector space as the kernel, furthermore it is closed under the Lie Bracket, since $\Tr(XY)=\Tr(YX)$
		\item If $B:\F^n \times \F^n \rightarrow \F$ is a bilinear form then the subspace: $$\mathfrak{o}_B(n,\F) = \{X \in \gl(n,\F)| B(Xv,w)+B(v,Xw)=0 \text{ for all } v,w\in \F^n\}$$ is a Lie Algebra.\\
		It is easily seen as a subspace because of bilinearity, now to check closure under the bracket:
		\begin{align*}
		B((XY-YX)v,w) &= B(XYv,w) - B(YXv,w) = -B(Yv,Xw) + B(Xv,Yw)\\
		&= B(v,YXw)- B(v,XYw) = -B(v,(XY-YX)w).
		\end{align*}
		\item The upper triangular and strictly upper triangular matrices are a Lie Algebra, in fact if the matrices are $\sum_{i<j} a_{ij} e_{ij}$ then since $[a_{ij}e_{ij},b_{kl}e_{kl}] = a_{ij}b_{kl}(\delta_{jk}e_{il}-\delta_{il}e_{kj})$
		if $j=k$ then $i<j=k<l$ and if $i=l$ then $k<l=i<j$, the same is valid for the space generated by $\{e_{ij},i\le j\}$
	\end{enumerate}
\end{ex}
\begin{ex}
	MORE EXAMPLES HERE TODO \label{MOREEXAMPLES}
\end{ex}
\begin{defi}
	Given a Lie Algebra $\g$ a derivation of $\g$ is a linear transformation $D\in\gl(\g)$ such that:
	$$D[X,Y]= [DX,Y]+[X,DY]$$
	The adjoint of an element $X \in \g$ is defined as $\ad(X) \in \gl(\g)$ in such a way that $\ad(X)(Y) = [X,Y]$\\
	A representation of $\g$ in a vector space $V$ is a Lie Algebra morphism $\rho$ from $\g$ to $\gl(V)$, meaning:
	$$\rho([X,Y]) = \rho(X)\rho(Y)-\rho(Y)\rho(X)$$
	The center of a Lie Algebra defined as $\z(\g) = \{Z \in \g | [Z,X] = 0 \text{ for all } X \in \g\}$ is an ideal.
\end{defi}
\begin{prop}
	The adjoint of an element is a derivation and the adjoint representation $\ad: X \mapsto \ad(X)$ is a representation from $\g$ into itself.
	\label{13adjointrepresentation}
\end{prop}
\begin{proof}
	Using the Jacobi identity:
	\begin{align*}
	\ad(X)([Y,Z]) &= [X,[Y,Z]] = -[Y,[Z,X]]-[Z,[X,Y]]\\
	&= [Y,[X,Z]] + [[X,Y],Z] = [Y,\ad(X)Z] + [\ad(X)Y,Z].
	\end{align*}
	\begin{align*}
	\ad([X,Y])(Z) &= [[X,Y],Z] = [X,[Y,Z]] + [Y,[Z,X]] \\
	&= [X,[Y,Z]] - [Y,[X,Z]] = \ad(X)\ad(Y)Z - \ad(Y)\ad(X)Z \ \text{ for all } Z \in \g.
	\end{align*}
\end{proof}\\
A useful way to think of representations is thinking them as linear actions that somehow preserve the structure of the Lie Algebra so we will choose a more direct way to define them.
\begin{defi}
	A $\g$-module is a vector space $V$ together with an operator $\cdot: \g \times V \rightarrow V$ in such a way that:
	\begin{enumerate}[label=(\alph*)]
		\item $X \cdot (v + w) = X \cdot v + X \cdot w$
		\item $(X+Y) \cdot v = X \cdot v + Y \cdot v$
		\item $[X,Y] \cdot v = X \cdot (Y \cdot v) - Y\cdot (X \cdot v)$
	\end{enumerate}
	\label{gmod}
\end{defi}
\begin{prop}
	Every $\g$-module $(V,\cdot)$ defines a representation and every representation $\rho$ defines a $\g$-module in such a way that $a \cdot v = \rho(a)v$ for every $a \in \g$ and $v \in V$
	\label{modequivrep}
\end{prop}
\begin{proof}
	The result is trivial, but for completeness:\\
	Given $V$ a $\g$-mod, then define $\rho(a) \in \gl(V)$ such that $\rho(a): v \mapsto a \cdot v$, it is in $\gl(V)$ if and only if the action satisfies $(a)$, it is a q linear morphism if and only if $(b)$ and it satisfies $\rho([X,Y])=\rho(X)\rho(Y)-\rho(Y)\rho(X)$ if and only if $(c)$
\end{proof}\\
Now we will move on to the first important results of Lie Theory, and for that we will define two series of ideals that play an important role. But before that, some clarification on notation:\\
Given subsets $\h$ and $k$ of a Lie Algebra $\g$ , we will define $[\h,k]$ as the set of all products from $\h$ and $k$, in case $\h$ and $k$ are vector spaces the order is irrelevant because of skew-symmetry and the resulting set is going to be a vector space by the bilinearity of the Lie Bracket . $$[\h,k] = \{[H,K] \in \g | H \in \h, K \in k\}$$
\begin{defi}
	The descendant series defined recurrently as:$$\begin{cases}
	\g^1 = \g, \\
	\g^n = [\g,\g^{n-1}].
	\end{cases}$$.\\
	The derived series is also defined recurrently: $$\begin{cases}
	\g^{(1)} = \g,\\
	\g^{(n)} = [\g^{(n-1)},\g^{(n-1)}].
	\end{cases}$$
	\label{13series}
\end{defi}
Some properties of these series are directly proven:
\begin{prop}
	\begin{enumerate}[label=\alph*.]
		\item They are decrescent series with respect to inclusion, that is:\\
		$\g \supset \g^2 \supset \cdots \supset \g^n \supset \cdots $
		and similarly $\g \supset \g^{(2)} \supset \cdots \supset \g^{(n)} \supset \cdots$
		\item All members of the series are ideals of $\g$
		\item For all $n$,  $\g^{(n)}\subset \g^n$
	\end{enumerate}
	\label{13seriesprop}
\end{prop}
\begin{proof}
	\begin{enumerate}[label=(\alph*)]
		\item For the case of the descendental series, consider an element in $X \in \g^n$ for $n > 2$ the case when $n=2$ follows directly from $\g$ being a Lie Algebra, by induction assume $g^{n}\subset g^{n-1}$ and then $X \in \g^{n+1}$ and then: $X=[Y,Z]$ for $Z \in \g^{n}$ and $Y \in \g$ then by induction $Y\in \g^{n-1}$ and we are done since $X \in [\g^{n-1},\g] = g^{n}$.\\
		For the case of the derived algebra, we also proceed by induction, the case $g^{(2)} = [g,g] \subset g$ is direct, assuming $g^{(n)} \subset g^{(n+1)}$ for $X \in g^{(n+1)}$ with $X=[Y,Z]$ for $Y,Z \in g^{(n)}$, then since $Y,Z \in g^{(n-1)}$ the result follows directly.\\
	\item For the descendental series, the result is direct from the previous result, $[g,g^n] = g^{n+1} \subset g^n$, it being a vector space follows from the previous discussion about the bracket of sets. For the derived series, we will use induction since $\g^{(1)}=\g \ideal \g$ trivially, then assume that $\g^{(n)} \ideal \g$ and let $X \in \g$ and $Y \in \g^{(n+1)}$ since $Y$ can be written as $[Z,W]$ for some $Z,W \in \g^{(n)}$, then:
	$$[X,Y] = [X,[Z,W]] = -[Z,[W,X]]-[W,[X,Z]] $$ 
	by induction $[W,X] = -[X,W] \in \g^{(n)}$ and therefore $[X,Y]$ is the sum of two elements in $\g^{(n+1)}$, given that it is a vector space then $[X,Y]$ is in $\g^{(n+1)}$, proving it is an ideal.
	\item By induction since $\g^{(n)}\subset \g$ then $\g^{(n+1)} = [\g^{(n)},\g^{(n)}] \subset [\g,\g^n] = \g^{n+1}$.
	\end{enumerate}
\end{proof}\\
Some type of algebras are classically special in the theory, with the ideal series being defined, then:
\begin{defi}

 An algebra is called \textbf{nilpotent} if $\g^n = 0$ for some $n$.\\
 An algebra is called \textbf{solvable} if $\g^{(n)}=0$ for some $n$.\\
 An algebra is \textbf{semi-simple} if it has no non-zero proper solvable ideals.\\
 An algebra is \textbf{simple} if it has no non-zero proper ideals.

\label{algebratypes}
\end{defi}
